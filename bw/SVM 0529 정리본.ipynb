{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 참고 자료\n",
    "\n",
    "###### 효율적인 SVM을 위한 Bagging\n",
    "###### https://m.blog.naver.com/cjh226/221359032956\n",
    "###### 2.3.6 결정 트리의 앙상블\n",
    "###### https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-3-6-%EA%B2%B0%EC%A0%95-%ED%8A%B8%EB%A6%AC%EC%9D%98-%EC%95%99%EC%83%81%EB%B8%94/\n",
    "###### 앙상블 학습과 랜덤 포레스트\n",
    "###### https://hoony-gunputer.tistory.com/entry/%ED%95%B8%EC%A6%88%EC%98%A8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-7%EA%B0%95-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5%EA%B3%BC-%EB%9E%9C%EB%8D%A4-%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8ensemble-RandomForest\n",
    "###### 랜덤 포레스트\n",
    "###### https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220979751089&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "###### 반복 교차 검증\n",
    "###### https://tensorflow.blog/tag/gridsearchcv/\n",
    "###### 3.3 scikit-learn의 전처리 기능\n",
    "###### https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/\n",
    "###### 커널 서포트 벡터 머신\n",
    "###### https://datascienceschool.net/view-notebook/69278a5de79449019ad1f51a614ef87c/\n",
    "###### 2.3.7 커널 서포트 벡터 머신\n",
    "###### https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-3-7-%EC%BB%A4%EB%84%90-%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0/\n",
    "###### 머신러닝 - 3. 서포트 벡터 머신 (SVM) 실습\n",
    "###### https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-3%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0-SVM-%EC%8B%A4%EC%8A%B5\n",
    "###### 교차검증 (cross-validation)\n",
    "###### https://homeproject.tistory.com/6\n",
    "###### scikit-learn의 SVM을 통한 분류(Classification)\n",
    "###### http://www.gisdeveloper.co.kr/?p=8180\n",
    "###### 22. Python - 다중 분류\n",
    "###### https://analysis-flood.tistory.com/77?category=725388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv를 가져와 넘파이배열 형태의 데이터셋으로 가공하는 과정\n",
    "import csv\n",
    "f1=open('winequality-red.csv','r',encoding='UTF-8')\n",
    "f2=open('winequality-white.csv','r',encoding='UTF-8')\n",
    "red_wine_data = csv.reader(f1)\n",
    "white_wine_data = csv.reader(f2)\n",
    "raw1=[]# 가공 전 레드와인 데이터를 넣어둘 리스트\n",
    "raw2=[]# 가공 전 화이트와인 데이터를 넣어둘 리스트\n",
    "\n",
    "total_data=[]# 가공된 모든 와인 데이터를 넣어둘 리스트\n",
    "\n",
    "features=[]# 특성 이름을 모아둘 리스트\n",
    "feat=[]# csv에 \"특성이름\" 의 형태로 들어가 있어서 \"\"을 제거하기 전 특성 이름 리스트\n",
    "target=[]# 정답인 등급을 모아둘 리스트\n",
    "\n",
    "for r in red_wine_data:\n",
    "    r=r[0].split(';')\n",
    "    r.insert(0,'1')#red가 1\n",
    "    raw1.append(r)\n",
    "\n",
    "for w in white_wine_data:\n",
    "    w=w[0].split(';')\n",
    "    w.insert(0,'0')#white가 0\n",
    "    raw2.append(w)\n",
    "\n",
    "raw1[0].pop(0)# 와인의 색 정보로 위에서 넣어둔 1을 빼냄\n",
    "feat=raw1[0]\n",
    "for f in feat:\n",
    "    s=f[1:len(f)-1]# \"\"을 제거하는 부분\n",
    "    features.append(s)\n",
    "features.insert(0,'color')\n",
    "\n",
    "# csv의 첫번째 행이 특성 정보이므로 그것을 없애는 작업\n",
    "raw1.pop(0)\n",
    "raw2.pop(0)\n",
    "\n",
    "for i1 in raw1:\n",
    "    total_data.append(i1)\n",
    "\n",
    "for i2 in raw2:\n",
    "    total_data.append(i2)\n",
    "\n",
    "for t in total_data:\n",
    "    target.append(t.pop())\n",
    "\n",
    "\n",
    "total_data=np.array(total_data)\n",
    "total_data = total_data.astype(np.float64)# 실행했을때 밑의 경고문이 떠서 추가\n",
    "\"\"\"\n",
    "FutureWarning:\n",
    "Beginning in version 0.22,\n",
    "arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'.\n",
    "It is recommended that you convert the array to a float dtype before using it in scikit-learn\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "\n",
    "target_6=copy.deepcopy(target) # 1~5 / 6~10\n",
    "      \n",
    "for i in range(0,len(target_6)):\n",
    "    if int(target_6[i])<5:\n",
    "        target_6[i]='0'\n",
    "    else:\n",
    "       target_6[i]='1'\n",
    "       \n",
    "target_6=np.array(target_6)\n",
    "target_6 = target_6.astype(np.float64)\n",
    "\n",
    "f1.close()\n",
    "f2.close()\n",
    "\n",
    "#위에서 copy가 일어나므로 밑에서 처리\n",
    "target=np.array(target)\n",
    "target = target.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 이진분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    total_data, target_6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train = StandardScaler()\n",
    "scaler_train.fit(x_train)\n",
    "X_train = scaler_train.transform(x_train)\n",
    "\n",
    "scaler_test = StandardScaler()\n",
    "scaler_test.fit(x_test)\n",
    "X_test = scaler_test.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearly Separable Data without Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.0%\n",
      "cross vaidation score : [0.96230769 0.96153846 0.96227868 0.96227868 0.96227868]\n",
      "0.9621364363119559\n",
      "stratified k-fold cross vaidation score : [0.96307692 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96302003 0.96302003 0.96302003]\n",
      "0.9621367784757616\n"
     ]
    }
   ],
   "source": [
    "# make a classifier and fit on training data\n",
    "clf_1 = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train classifier \n",
    "clf_1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_1_predictions = clf_1.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(clf_1.score(X_test, y_test) * 100 ))\n",
    "\n",
    "score_1_cv = cross_val_score(clf_1, total_data, target_6)\n",
    "print('cross vaidation score : %s'%score_1_cv)\n",
    "print(score_1_cv.mean())\n",
    "\n",
    "skf=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "score_1_skf = cross_val_score(clf_1, total_data, target_6, cv=skf)\n",
    "print('stratified k-fold cross vaidation score : %s'%score_1_skf)\n",
    "print(score_1_skf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearly Separable Data with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 96.28489326765188%\n",
      "Test Accuracy: 96.0%\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'C': 0.001}\n",
      "Best Estimators:\n",
      " SVC(C=0.001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Train Accuracy: 96.28489326765188%\n",
      "Test Accuracy: 96.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "# make a classifier and fit on training data\n",
    "clf_2 = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "# Train classifier \n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_2_predictions = clf_2.predict(X_test)\n",
    "print(\"Train Accuracy: {}%\".format(clf_2.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf_2.score(X_test, y_test) * 100 ))\n",
    "\n",
    "# Parameter Grid\n",
    "param_2_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Make grid search classifier\n",
    "clf_2_grid = GridSearchCV(svm.SVC(), param_2_grid, verbose=1)\n",
    "\n",
    "# Train the classifier\n",
    "clf_2_grid.fit(X_train, y_train)\n",
    "\n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_2_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_2_grid.best_estimator_)\n",
    "\n",
    "print(\"Train Accuracy: {}%\".format(clf_2_grid.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf_2_grid.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 96.28489326765188%\n",
      "Test Accuracy: 96.0%\n",
      "cross vaidation score : [0.96230769 0.96153846 0.96227868 0.96227868 0.96227868]\n",
      "0.9621364363119559\n",
      "stratified k-fold cross vaidation score : [0.96307692 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96302003 0.96302003 0.96302003]\n",
      "0.9621367784757616\n"
     ]
    }
   ],
   "source": [
    "# make a classifier and fit on training data\n",
    "clf_2_bp = svm.SVC(C=0.001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "# Train classifier \n",
    "clf_2_bp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_2_bppredictions = clf_2_bp.predict(X_test)\n",
    "print(\"Train Accuracy: {}%\".format(clf_2_bp.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf_2_bp.score(X_test, y_test) * 100 ))\n",
    "\n",
    "score_2_bp_cv = cross_val_score(clf_2_bp, total_data, target_6)\n",
    "print('cross vaidation score : %s'%score_2_bp_cv)\n",
    "print(score_2_bp_cv.mean())\n",
    "\n",
    "skf=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "score_2_bp_skf = cross_val_score(clf_2_bp, total_data, target_6, cv=skf)\n",
    "print('stratified k-fold cross vaidation score : %s'%score_2_bp_skf)\n",
    "print(score_2_bp_skf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NonLinearly Separable Data with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.3111658456486%\n",
      "Test Accuracy: 96.3076923076923%\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 245 out of 245 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'C': 1000, 'gamma': 1000}\n",
      "Best Estimators:\n",
      " SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1000, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# make a classifier\n",
    "clf_3 = svm.SVC(C = 10.0, kernel='rbf', gamma=0.1)\n",
    "\n",
    "# Train classifier\n",
    "clf_3.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_3_predictions = clf_3.predict(X_test)\n",
    "print(\"Train Accuracy: {}%\".format(clf_3.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf_3.score(X_test, y_test) * 100 ))\n",
    "\n",
    "# Parameter Grid\n",
    "param_3_grid = {'C': [1000, 100, 10, 1, 0.1, 0.01, 0.001], \n",
    "                'gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "# Make grid search classifier\n",
    "clf_3_grid = GridSearchCV(svm.SVC(), param_3_grid, verbose=1)\n",
    "\n",
    "# Train the classifier\n",
    "clf_3_grid.fit(X_train, y_train)\n",
    "\n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_3_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_3_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.0%\n",
      "Test Accuracy: 96.0%\n",
      "cross vaidation score : [0.96230769 0.96153846 0.96227868 0.96227868 0.96227868]\n",
      "0.9621364363119559\n",
      "stratified k-fold cross vaidation score : [0.96615385 0.96461538 0.96615385 0.96307692 0.96461538 0.96307692\n",
      " 0.96153846 0.96302003 0.96764253 0.96918336]\n",
      "0.9649076686025838\n"
     ]
    }
   ],
   "source": [
    "# make a classifier and fit on training data\n",
    "clf_3_bp = svm.SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1000, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "# Train classifier \n",
    "clf_3_bp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_3_bppredictions = clf_3_bp.predict(X_test)\n",
    "print(\"Train Accuracy: {}%\".format(clf_3_bp.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf_3_bp.score(X_test, y_test) * 100 ))\n",
    "\n",
    "score_3_bp_cv = cross_val_score(clf_3_bp, total_data, target_6)\n",
    "print('cross vaidation score : %s'%score_3_bp_cv)\n",
    "print(score_3_bp_cv.mean())\n",
    "\n",
    "skf=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "score_3_bp_skf = cross_val_score(clf_3_bp, total_data, target_6, cv=skf)\n",
    "print('stratified k-fold cross vaidation score : %s'%score_3_bp_skf)\n",
    "print(score_3_bp_skf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 이진분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    total_data, target, random_state=0)\n",
    "\n",
    "scaler_train = StandardScaler()\n",
    "scaler_train.fit(x_train)\n",
    "X_train = scaler_train.transform(x_train)\n",
    "\n",
    "scaler_test = StandardScaler()\n",
    "scaler_test.fit(x_test)\n",
    "X_test = scaler_test.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.3111658456486%\n",
      "Test Accuracy: 96.3076923076923%\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 245 out of 245 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'C': 1000, 'gamma': 1000}\n",
      "Best Estimators:\n",
      " SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1000, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# make a classifier\n",
    "clf = svm.SVC(C = 10.0, kernel='rbf', gamma=0.1)\n",
    "\n",
    "# Train classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Train Accuracy: {}%\".format(clf.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))\n",
    "\n",
    "# Parameter Grid\n",
    "param_grid = {'C': [1000, 100, 10, 1, 0.1, 0.01, 0.001], 'gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "# Make grid search classifier\n",
    "clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=1)\n",
    "\n",
    "# Train the classifier\n",
    "clf_grid.fit(X_train, y_train)\n",
    "\n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.0%\n",
      "Test Accuracy: 96.0%\n",
      "cross vaidation score : [0.43615385 0.43615385 0.43725943 0.43879908 0.43725943]\n",
      "0.43712512583644225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SomeoneFromSomewhere\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified k-fold cross vaidation score : [0.58923077 0.6        0.61230769 0.61538462 0.60923077 0.59076923\n",
      " 0.61076923 0.61941448 0.62865948 0.59938367]\n",
      "0.6075149934810952\n"
     ]
    }
   ],
   "source": [
    "# make a classifier and fit on training data\n",
    "clf_bp = svm.SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1000, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "# Train classifier \n",
    "clf_bp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_bp_predictions = clf_bp.predict(X_test)\n",
    "print(\"Train Accuracy: {}%\".format(clf_bp.score(X_train, y_train) * 100 ))\n",
    "print(\"Test Accuracy: {}%\".format(clf_bp.score(X_test, y_test) * 100 ))\n",
    "\n",
    "score_bp_cv = cross_val_score(clf_bp, total_data, target)\n",
    "print('cross vaidation score : %s'%score_bp_cv)\n",
    "print(score_bp_cv.mean())\n",
    "\n",
    "skf=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "score_bp_skf = cross_val_score(clf_bp, total_data, target, cv=skf)\n",
    "print('stratified k-fold cross vaidation score : %s'%score_bp_skf)\n",
    "print(score_bp_skf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified k-fold cross vaidation score : [0.57230769 0.59615385 0.58352579 0.59276366 0.58891455]\n",
      "0.586733108308166\n"
     ]
    }
   ],
   "source": [
    "skf_5=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "score_bp_skf_5 = cross_val_score(clf_bp, total_data, target, cv=skf_5)\n",
    "print('stratified k-fold cross vaidation score : %s'%score_bp_skf_5)\n",
    "print(score_bp_skf_5.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수:1625 오류개수:62\n",
      "정확도: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nn_estimators=10\\n총 테스트 개수:1625 오류개수:60\\n정확도: 0.96\\n\\nn_estimators=20\\n총 테스트 개수:1625 오류개수:62\\n정확도: 0.96\\n\\nn_estimators=40\\n총 테스트 개수:1625 오류개수:64\\n정확도: 0.96\\n\\nn_estimators=80\\n총 테스트 개수:1625 오류개수:62\\n정확도: 0.96\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ml = RandomForestClassifier(criterion='entropy',n_estimators=1000,\n",
    "                           n_jobs=-1, random_state=1)\n",
    "\n",
    "ml.fit(X_train, y_train)\n",
    "y_pred = ml.predict(X_test)\n",
    "print('총 테스트 개수:%d 오류개수:%d'%(len(y_test), (y_test != y_pred).sum()))\n",
    "print('정확도: %.2f'%accuracy_score(y_test, y_pred))\n",
    "\n",
    "'''\n",
    "n_estimators=10\n",
    "총 테스트 개수:1625 오류개수:60\n",
    "정확도: 0.96\n",
    "\n",
    "n_estimators=20\n",
    "총 테스트 개수:1625 오류개수:62\n",
    "정확도: 0.96\n",
    "\n",
    "n_estimators=40\n",
    "총 테스트 개수:1625 오류개수:64\n",
    "정확도: 0.96\n",
    "\n",
    "n_estimators=80\n",
    "총 테스트 개수:1625 오류개수:62\n",
    "정확도: 0.96\n",
    "\n",
    "n_estimators=1000\n",
    "총 테스트 개수:1625 오류개수:62\n",
    "정확도: 0.96\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
