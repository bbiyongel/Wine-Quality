{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0604\n",
    "- kaggle에서 3진분류를 한 결과, __RF, GradientBoostingClassifier__ 이 두개가 가장 결과가 좋았다.  \n",
    "- 3~9분류, 이진분류에서도 실험해보고자 함.  \n",
    "- 이전에 svm을 실험했을 때 11개 특성을 모두 이용하는게 가장 잘 나왔었음. 그리고 차원축소 안하는게 가장 결과가 좋았었었다. 따라서 이번에는 test할겸 11개를 다 넣어서 실험함. 따로 처리(커널)등을 하지 않고 그냥 분류 결과만 비교함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (0.82)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from xgboost) (1.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (20.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data pre-processing\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#  Data splitting and model parameter search\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine 데이터셋의 크기: (6463, 14)\n",
      "\n",
      "wine 데이터셋의 키: Index([u'type', u'fixed acidity', u'volatile acidity', u'citric acid',\n",
      "       u'residual sugar', u'chlorides', u'free sulfur dioxide',\n",
      "       u'total sulfur dioxide', u'density', u'pH', u'sulphates', u'alcohol',\n",
      "       u'quality', u'binaryQuality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"./data/binary_winequalityN.csv\")\n",
    "#dataw=pd.read_csv(\"./data/1_white.csv\")\n",
    "#datar=pd.read_csv(\"./data/1_red.csv\")\n",
    "\n",
    "data=data.dropna(axis=0)  ##없애버림, 평균값 넣으려면 axis=0대신에 inplate=True 사용\n",
    "#dataw=dataw.dropna(axis=0)\n",
    "\n",
    "print \"wine 데이터셋의 크기:\" ,data.shape\n",
    "print \"\\nwine 데이터셋의 키:\", data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 키\n",
    "['type', 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6463 entries, 0 to 6496\n",
      "Data columns (total 14 columns):\n",
      "type                    6463 non-null object\n",
      "fixed acidity           6463 non-null float64\n",
      "volatile acidity        6463 non-null float64\n",
      "citric acid             6463 non-null float64\n",
      "residual sugar          6463 non-null float64\n",
      "chlorides               6463 non-null float64\n",
      "free sulfur dioxide     6463 non-null float64\n",
      "total sulfur dioxide    6463 non-null float64\n",
      "density                 6463 non-null float64\n",
      "pH                      6463 non-null float64\n",
      "sulphates               6463 non-null float64\n",
      "alcohol                 6463 non-null float64\n",
      "quality                 6463 non-null int64\n",
      "binaryQuality           6463 non-null int64\n",
      "dtypes: float64(11), int64(2), object(1)\n",
      "memory usage: 757.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 데이터와 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train에 적재하기 위한 2차원 배열의 특성 dataset을 만든다.\n",
    "#6463*11(?) 사이즈\n",
    "\n",
    "#실험의 편의성을 위해 data마다 이름을 붙였다.\n",
    "f1=data['fixed acidity']\n",
    "f2=data['volatile acidity']\n",
    "f3=data['citric acid']\n",
    "f4=data['residual sugar']\n",
    "f5=data['chlorides']\n",
    "f6=data['free sulfur dioxide']\n",
    "f7=data['total sulfur dioxide']\n",
    "f8=data['density']\n",
    "f9=data['pH']\n",
    "f10=data['sulphates']\n",
    "f11=data['alcohol']\n",
    "\n",
    "\n",
    "c_data=np.c_[f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원본 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4524, 11)\n",
      "y_train 크기:  (4524,)\n",
      "X_val 크기:  (970, 11)\n",
      "y_val 크기:  (970,)\n",
      "X_test 크기:  (969, 11)\n",
      "y_test 크기:  (969,)\n"
     ]
    }
   ],
   "source": [
    "## 원본\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(c_data, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(c_data, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_val 크기: \", X_val.shape\n",
    "print \"y_val 크기: \", y_val.shape\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling modules\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest, extra_trees, svm, mlp, adaboost, gradient boosting, xgbc\n",
    "\n",
    "- 엑스트라 트리는 트리를 더욱 무작위하게 만들기 위해 최적의 임곗값을 찾는 대신에 후보 특성을 사용하여 무작위로 분할한 후 최상의 분할을 선택한다.\n",
    "- 아다부스트는 반복마다 샘플의 가중치를 수정\n",
    "- 그래디언트 부스팅은 아다부스트처럼 예측기를 순차적으로 추가, 이전 예측기의 잔여 오차에 새로운 예측기를 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=10000, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=5000, random_state=42)\n",
    "svm_clf = LinearSVC(max_iter=10000, random_state=42)\n",
    "mlp_clf = MLPClassifier(max_iter=10000,random_state=42)\n",
    "ada_clp=AdaBoostClassifier(n_estimators=10000,random_state=42)\n",
    "gradient_boosting_clf=GradientBoostingClassifier(n_estimators=10000,random_state=42)\n",
    "xgbc_clf=xgb.XGBClassifier(base_score=0.5, colsample_bylevel=1, n_jobs=1,\n",
    "                       colsample_bytree=1, gamma=0.0001, max_delta_step=0, random_state=42, \n",
    "                       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf, gradient_boosting_clf,xgbc_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Train prediction machine: \", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6865979381443299"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train prediction machine: ', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train prediction machine: ', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "###10000으로 하니까 셀이 자꾸 죽어서 나눴음\n",
    "estimators2 = [svm_clf, mlp_clf]\n",
    "for estimator in estimators2:\n",
    "    print(\"Train prediction machine: \", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5030927835051546, 0.534020618556701]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train prediction machine: ', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
      "              n_iter_no_change=None, presort='auto', random_state=42,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False))\n",
      "('Train prediction machine: ', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0.0001, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=42, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1))\n"
     ]
    }
   ],
   "source": [
    "###10000으로 하니까 셀이 자꾸 죽어서 나눴음\n",
    "estimators3 = [gradient_boosting_clf,xgbc_clf]\n",
    "for estimator in estimators3:\n",
    "    print(\"Train prediction machine: \", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6618556701030928, 0.5979381443298969]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quality일 때  \n",
    "#### 기본값-svc는 10000, 나머지는 아마 10?\n",
    "[0.668041237113402,\n",
    "0.6391752577319587,\n",
    "0.5030927835051546,\n",
    "0.534020618556701,\n",
    "0.5989690721649484,\n",
    "0.5979381443298969]\n",
    "\n",
    "#### max_iter 1000으로\n",
    "[0.6907216494845361,\n",
    "0.6865979381443299,\n",
    "0.3391752577319588,\n",
    "0.534020618556701,\n",
    "0.6608247422680412,\n",
    "0.5979381443298969]\n",
    "\n",
    "#### max_iter 10000으로\n",
    "[0.6927835051546392, 0.6865979381443299(5000으로함), 0.5030927835051546, 0.534020618556701, 0.6618556701030928, 0.5979381443298969]\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 이진분류일 때\n",
    "[0.7958762886597938,\n",
    "0.8123711340206186,\n",
    "0.6597938144329897,\n",
    "0.7381443298969073,\n",
    "0.7762886597938145,\n",
    "0.7804123711340206]\n",
    "\n",
    "#### max_iter 1000으로\n",
    "[0.8216494845360824,\n",
    "0.8257731958762886,\n",
    "0.42061855670103093,\n",
    "0.7381443298969073,\n",
    "0.8134020618556701,\n",
    "0.7804123711340206]\n",
    "\n",
    "#### max_iter 10000으로\n",
    "[0.822680412371134, 0.8288659793814434, 0.6597938144329897, 0.7381443298969073, 0.8103092783505155, 0.7804123711340206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
