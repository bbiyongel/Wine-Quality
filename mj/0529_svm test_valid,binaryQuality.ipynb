{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0528\n",
    "차원축소를 한 뒤 SVM을 적용해보자(이진분류)\n",
    "\n",
    "#### valid로 검증해보기\n",
    "- training/validation/Testing을 70:15:15로 나눈다.\n",
    "- validation set으로 최상의 성능을 내는 옵션을 선택한다.\n",
    "- validation set으로 선택된 것을 test set에 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 추가적으로 확인해봐야할것(다음시간에..)\n",
    "\n",
    "- overfitting등의 문제에 대해 더 찾아보자\n",
    "- PCA를 이용해서 주성분분석을 하여 선형차원축소를 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/49/7e10686647f741bd9c8918b0decdb94135b542fe372ca1100739b8529503/xgboost-0.82-py2.py3-none-manylinux1_x86_64.whl (114.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 114.0MB 256kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from xgboost) (1.14.3)\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 17.2MB/s ta 0:00:01\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-20.1.1\n",
      "\u001b[33mYou are using pip version 20.1.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data pre-processing\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#  Data splitting and model parameter search\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling modules\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine 데이터셋의 크기: (6463, 14)\n",
      "\n",
      "wine 데이터셋의 키: Index([u'type', u'fixed acidity', u'volatile acidity', u'citric acid',\n",
      "       u'residual sugar', u'chlorides', u'free sulfur dioxide',\n",
      "       u'total sulfur dioxide', u'density', u'pH', u'sulphates', u'alcohol',\n",
      "       u'quality', u'binaryQuality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"./data/binary_winequalityN.csv\")\n",
    "#dataw=pd.read_csv(\"./data/1_white.csv\")\n",
    "#datar=pd.read_csv(\"./data/1_red.csv\")\n",
    "\n",
    "data=data.dropna(axis=0)  ##없애버림, 평균값 넣으려면 axis=0대신에 inplate=True 사용\n",
    "#dataw=dataw.dropna(axis=0)\n",
    "\n",
    "print \"wine 데이터셋의 크기:\" ,data.shape\n",
    "print \"\\nwine 데이터셋의 키:\", data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 키\n",
    "['type', 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6463 entries, 0 to 6496\n",
      "Data columns (total 14 columns):\n",
      "type                    6463 non-null object\n",
      "fixed acidity           6463 non-null float64\n",
      "volatile acidity        6463 non-null float64\n",
      "citric acid             6463 non-null float64\n",
      "residual sugar          6463 non-null float64\n",
      "chlorides               6463 non-null float64\n",
      "free sulfur dioxide     6463 non-null float64\n",
      "total sulfur dioxide    6463 non-null float64\n",
      "density                 6463 non-null float64\n",
      "pH                      6463 non-null float64\n",
      "sulphates               6463 non-null float64\n",
      "alcohol                 6463 non-null float64\n",
      "quality                 6463 non-null int64\n",
      "binaryQuality           6463 non-null int64\n",
      "dtypes: float64(11), int64(2), object(1)\n",
      "memory usage: 757.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 데이터와 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train에 적재하기 위한 2차원 배열의 특성 dataset을 만든다.\n",
    "#6463*11(?) 사이즈\n",
    "\n",
    "#실험의 편의성을 위해 data마다 이름을 붙였다.\n",
    "f1=data['fixed acidity']\n",
    "f2=data['volatile acidity']\n",
    "f3=data['citric acid']\n",
    "f4=data['residual sugar']\n",
    "f5=data['chlorides']\n",
    "f6=data['free sulfur dioxide']\n",
    "f7=data['total sulfur dioxide']\n",
    "f8=data['density']\n",
    "f9=data['pH']\n",
    "f10=data['sulphates']\n",
    "f11=data['alcohol']\n",
    "\n",
    "\n",
    "c_data=np.c_[f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어떤 데이터를 적재?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원본 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4524, 11)\n",
      "y_train 크기:  (4524,)\n",
      "X_val 크기:  (970, 11)\n",
      "y_val 크기:  (970,)\n",
      "X_test 크기:  (969, 11)\n",
      "y_test 크기:  (969,)\n"
     ]
    }
   ],
   "source": [
    "## 원본\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(c_data, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(c_data, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_val 크기: \", X_val.shape\n",
    "print \"y_val 크기: \", y_val.shape\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4524, 3)\n",
      "y_train 크기:  (4524,)\n",
      "X_val 크기:  (970, 3)\n",
      "y_val 크기:  (970,)\n",
      "X_test 크기:  (969, 3)\n",
      "y_test 크기:  (969,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "'''\n",
    "##T-SNE 2차원\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced = tsne.fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "'''\n",
    "'''\n",
    "##T-SNE 3차원\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "X_reduced = tsne.fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "#--------------\n",
    "'''\n",
    "##T-SNE 2차원\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced = tsne.fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "\n",
    "'''\n",
    "##T-SNE 3차원\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "X_reduced = tsne.fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_val 크기: \", X_val.shape\n",
    "print \"y_val 크기: \", y_val.shape\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4524, 3)\n",
      "y_train 크기:  (4524,)\n",
      "X_val 크기:  (970, 3)\n",
      "y_val 크기:  (970,)\n",
      "X_test 크기:  (969, 3)\n",
      "y_test 크기:  (969,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "'''\n",
    "##PCA 2차원\n",
    "X_pca_reduced = PCA(n_components=2, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "'''\n",
    "'''\n",
    "##PCA 3차원\n",
    "X_pca_reduced = PCA(n_components=3, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "'''\n",
    "##PCA 2차원\n",
    "X_pca_reduced = PCA(n_components=2, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "##PCA 3차원\n",
    "X_pca_reduced = PCA(n_components=3, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_val 크기: \", X_val.shape\n",
    "print \"y_val 크기: \", y_val.shape\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4524, 3)\n",
      "y_train 크기:  (4524,)\n",
      "X_val 크기:  (970, 3)\n",
      "y_val 크기:  (970,)\n",
      "X_test 크기:  (969, 3)\n",
      "y_test 크기:  (969,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "##LLE 2차원\n",
    "'''\n",
    "X_lle_reduced = LocallyLinearEmbedding(n_components=2, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lle_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "'''\n",
    "##LLE 3차원\n",
    "X_lle_reduced = LocallyLinearEmbedding(n_components=3, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lle_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "##---\n",
    "'''\n",
    "##LLE 2차원\n",
    "\n",
    "X_lle_reduced = LocallyLinearEmbedding(n_components=2, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lle_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "'''\n",
    "##LLE 3차원\n",
    "X_lle_reduced = LocallyLinearEmbedding(n_components=3, random_state=42).fit_transform(c_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lle_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_val 크기: \", X_val.shape\n",
    "print \"y_val 크기: \", y_val.shape\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4524, 1)\n",
      "y_train 크기:  (4524,)\n",
      "X_val 크기:  (970, 1)\n",
      "y_val 크기:  (970,)\n",
      "X_test 크기:  (969, 1)\n",
      "y_test 크기:  (969,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "'''\n",
    "##LDA 2차원\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=2).fit_transform(c_data, data['quality'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "'''\n",
    "'''\n",
    "##LDA 3차원\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=3).fit_transform(c_data, data['quality'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "'''\n",
    "##LDA 6차원\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=6).fit_transform(c_data, data['quality'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda_reduced, data['quality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "\n",
    "##---\n",
    "'''\n",
    "##LDA 2차원\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=2).fit_transform(c_data, data['binaryQuality'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "\n",
    "'''\n",
    "##LDA 3차원\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=3).fit_transform(c_data, data['binaryQuality'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "'''\n",
    "##LDA 6차원\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=6).fit_transform(c_data, data['quality'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda_reduced, data['binaryQuality'],test_size=0.3,random_state=0)\n",
    "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test,test_size=0.5,random_state=0)\n",
    "'''\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_val 크기: \", X_val.shape\n",
    "print \"y_val 크기: \", y_val.shape\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OvA를 사용하여 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=100000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "lin_clf = LinearSVC(max_iter=100000, random_state=42)\n",
    "lin_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 set에 대한 예측을 만들어 정확도를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7263483642793988"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lin_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality로 했을 때\n",
    "- 일반: 0.5347038019451813\n",
    "\n",
    "\n",
    "- T-SNE 2차원: \n",
    "- T-SNE 3차원: 0.4398762157382847\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.4394341290893015\n",
    "- PCA 3차원: 0.4365605658709107\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.4328028293545535\n",
    "- LLE 3차원:0.4334659593280283\n",
    "\n",
    "\n",
    "- LDA 2차원:0.5327144120247569\n",
    "- LDA 3차원:0.5327144120247569\n",
    "- LDA 6차원:0.5360300618921309\n",
    "\n",
    "### 이진분류로 했을 때\n",
    "- 일반: 0.7263483642793988\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.6262157382847038\n",
    "- T-SNE 3차원: 0.6328470380194519\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.6350574712643678 \n",
    "- PCA 3차원: 0.6324049513704686\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.632183908045977\n",
    "- LLE 3차원:0.6317418213969939\n",
    "\n",
    "\n",
    "- LDA 2차원:0.7413793103448276\n",
    "- LDA 3차원:0.7413793103448276\n",
    "- LDA 6차원: 0.7409372236958444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data의 scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_val_scaled = scaler.transform(X_val.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=100000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(max_iter=100000, random_state=42)\n",
    "lin_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7427055702917772"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality로 했을 때\n",
    "- 일반: 0.5340406719717065\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.4321396993810787\n",
    "- T-SNE 3차원: 0.4398762157382847\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.4378868258178603\n",
    "- PCA 3차원: 0.4363395225464191\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.43567639257294427\n",
    "- LLE 3차원: 0.4376657824933687\n",
    "\n",
    "\n",
    "- LDA 2차원: 0.5327144120247569\n",
    "- LDA 3차원: 0.5327144120247569\n",
    "- LDA 6차원: 0.5360300618921309\n",
    "\n",
    "### 이진분류로 했을 때\n",
    "- 일반: 0.7427055702917772\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.6262157382847038\n",
    "- T-SNE 3차원: 0.6328470380194519\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.6359416445623343\n",
    "- PCA 3차원: 0.6339522546419099\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.6317418213969939\n",
    "- LLE 3차원:0.632183908045977\n",
    "\n",
    "\n",
    "- LDA 2차원:0.7413793103448276\n",
    "- LDA 3차원:0.7413793103448276\n",
    "- LDA 6차원: 0.7409372236958444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF 커널 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(gamma='auto', decision_function_shape=\"ovr\")\n",
    "svm_clf.fit(X_train_scaled[:4847], y_train[:4847]) ##4847개 data로 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8006189213085765"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality로 했을 때\n",
    "- 일반: 0.6080901856763926\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.44297082228116713\n",
    "- T-SNE 3차원: 0.4573386383731211\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.4493810786914235\n",
    "- PCA 3차원: 0.45755968169761274\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.4496021220159151\n",
    "- LLE 3차원: 0.4535809018567639\n",
    "\n",
    "\n",
    "- LDA 2차원:0.5501768346595933\n",
    "- LDA 3차원:0.5534924845269673\n",
    "- LDA 6차원:0.5864279398762158\n",
    "\n",
    "### 이진분류로 했을 때\n",
    "- 일반: 0.8006189213085765\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.6315207780725022\n",
    "- T-SNE 3차원: 0.6522988505747126\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.6478779840848806\n",
    "- PCA 3차원: 0.6538461538461539\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.6412466843501327\n",
    "- LLE 3차원:0.6410256410256411\n",
    "\n",
    "\n",
    "- LDA 2차원:0.7393899204244032\n",
    "- LDA 3차원:0.7393899204244032\n",
    "- LDA 6차원:0.7769672855879752"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증 이용한 랜덤 서치로 hyper parameter 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7734305923961097"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, cv=3, n_iter=10, verbose=2, n_jobs=-1)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "rnd_search_cv.best_estimator_\n",
    "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)\n",
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961980548187445"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality로 했을 때\n",
    "- 일반: 0.6987179487179487\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.43258178603006187\n",
    "- T-SNE 3차원: 0.4316976127320955\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.4458443854995579\n",
    "- PCA 3차원: 0.4465075154730327\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.4442970822281167\n",
    "- LLE 3차원: 0.4498231653404067\n",
    "\n",
    "\n",
    "- LDA 2차원:0.5446507515473032\n",
    "- LDA 3차원:0.5517241379310345\n",
    "- LDA 6차원:0.5820070733863837\n",
    "\n",
    "### 이진분류로 했을 때\n",
    "- 일반: 0.8156498673740054\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.6315207780725022\n",
    "- T-SNE 3차원: 0.6315207780725022\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.6361626878868258\n",
    "- PCA 3차원: 0.6472148541114059\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.6381520778072503\n",
    "- LLE 3차원:0.637709991158267\n",
    "\n",
    "\n",
    "- LDA 2차원:0.7411582670203359\n",
    "- LDA 3차원:0.7431476569407603\n",
    "- LDA 6차원:0.7765251989389921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765979381443299"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##val\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_val_scaled)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality로 했을 때\n",
    "#### - 일반: 0.6010309278350515\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.4463917525773196\n",
    "- T-SNE 3차원: 0.44536082474226807\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.4556701030927835\n",
    "- PCA 3차원: 0.45979381443298967\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.45463917525773195\n",
    "- LLE 3차원: 0.45257731958762887\n",
    "\n",
    "\n",
    "- LDA 2차원: 0.5381443298969072\n",
    "- LDA 3차원:0.5422680412371134\n",
    "- LDA 6차원:0.545360824742268\n",
    "\n",
    "### 이진분류로 했을 때\n",
    "#### - 일반: 0.7731958762886598\n",
    "\n",
    "\n",
    "- T-SNE 2차원: 0.6412371134020619\n",
    "- T-SNE 3차원: 0.6412371134020619\n",
    "\n",
    "\n",
    "- PCA 2차원: 0.6484536082474227\n",
    "- PCA 3차원: 0.6494845360824743\n",
    "\n",
    "\n",
    "- LLE 2차원: 0.6443298969072165\n",
    "- LLE 3차원:0.6422680412371135\n",
    "\n",
    "\n",
    "- LDA 2차원:0.7350515463917526\n",
    "- LDA 3차원:0.7360824742268042\n",
    "- LDA 6차원:0.7556701030927835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5717234262125903"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 가장 높게 나온 것에 대해서 수행\n",
    "X_test_scaled = scaler.fit_transform(X_test.astype(np.float32))\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7760577915376677"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 가장 높게 나온 것에 대해서 수행\n",
    "X_test_scaled = scaler.fit_transform(X_test.astype(np.float32))\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
