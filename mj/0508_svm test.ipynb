{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 복잡한 분류 문제에 적합  \n",
    "\n",
    "- 선형/비선형  \n",
    "\n",
    "- 대표적인 이진 분류 모델  \n",
    "\n",
    "- 왜 인기?  \n",
    "    - 분류를 할 때 가장 최적의 선을 찾아줌(두 데이터와 선의 거리까지 고려)\n",
    "\n",
    "- vector 선으로 분류\n",
    "\n",
    "\n",
    "### 선형\n",
    "- 라지 마진 분류\n",
    "    - 직선으로 경계가 나눌 수 있는가?\n",
    "    - 특성이 2개\n",
    "    - 결정 경계가 샘플에 가까우면 안된다.\n",
    "    \n",
    "- 하드 마진 분류\n",
    "    - 이상치(선형 분류가 되지만, 하나(이상치)가 반대쪽 영역에 가있음)에 민감하다\n",
    "    - 데이터가 선형으로 분류되어야 한다.\n",
    "    \n",
    "- 소프트 마진 분류\n",
    "    - 하드 마진 분류에 비해 이상치에 덜민감(유연한 모델)\n",
    "    - 'C'(하이프파라미터)를 이용하여 균형을 조정한다.\n",
    "\n",
    "\n",
    "### 비선형\n",
    "##### 선형은 특성이 2개였지만, 비선형은 특성을 추가하여서 선형 구분 데이터셋을 만든다.\n",
    "\n",
    "\n",
    "\n",
    "### 0501\n",
    "overfitting 등의 문제가 생길 수 있다고 함. 아직 함수 하나하나를 이해하지는 못했음. 육안으로 봤을 때에는 PCA를 통해 차원 축소를 한 이후에 해야한다고 생각함.하지만 실제로 정확도가 더 높게 나왔다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0508\n",
    "\n",
    "- 특성 11개를 다 보지 않고 가장 연관이 있다고 판단된 특성 7개를 뽑아서 test하였다.\n",
    "\n",
    "- 우리가 가진 data값 : 수치형(정량형)\n",
    "\n",
    "- feature 5인 chlorides가 일정해서 사용할 수 없다는 식으로 나오는데 수가 다른 것에 비해서 작아서 그런가?\n",
    "\n",
    "- __아무튼 ANOVA (분산 분석)의 F-값 계산해서 최고로 연관성이 있다고 나온 특성 7개만 뽑았다. quality, Binary quality 두개 다 실시__\n",
    "<br>\n",
    "\n",
    "- 그 결과 quality, Binary quality 모두에서 __특성값 11개일 때보다 정확도가 낮게__ 나왔다. RBF 커널 적용 전까지는 괜찮다가 __RBF커널을 적용하면 특성의 개수가 줄어들수록 정확도가 감소한다.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 추가적으로 확인해봐야할것(다음시간에..)\n",
    "\n",
    "- overfitting등의 문제에 대해 더 찾아보자\n",
    "- PCA를 이용해서 주성분분석을 하여 선형차원축소를 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (0.82)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from xgboost) (1.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data pre-processing\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#  Data splitting and model parameter search\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling modules\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine 데이터셋의 크기: (6463, 14)\n",
      "\n",
      "wine 데이터셋의 키: Index([u'type', u'fixed acidity', u'volatile acidity', u'citric acid',\n",
      "       u'residual sugar', u'chlorides', u'free sulfur dioxide',\n",
      "       u'total sulfur dioxide', u'density', u'pH', u'sulphates', u'alcohol',\n",
      "       u'quality', u'binaryQuality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"./data/binary_winequalityN.csv\")\n",
    "#dataw=pd.read_csv(\"./data/1_white.csv\")\n",
    "#datar=pd.read_csv(\"./data/1_red.csv\")\n",
    "\n",
    "data=data.dropna(axis=0)  ##없애버림, 평균값 넣으려면 axis=0대신에 inplate=True 사용\n",
    "#dataw=dataw.dropna(axis=0)\n",
    "\n",
    "print \"wine 데이터셋의 크기:\" ,data.shape\n",
    "print \"\\nwine 데이터셋의 키:\", data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 키\n",
    "['type', 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6463 entries, 0 to 6496\n",
      "Data columns (total 14 columns):\n",
      "type                    6463 non-null object\n",
      "fixed acidity           6463 non-null float64\n",
      "volatile acidity        6463 non-null float64\n",
      "citric acid             6463 non-null float64\n",
      "residual sugar          6463 non-null float64\n",
      "chlorides               6463 non-null float64\n",
      "free sulfur dioxide     6463 non-null float64\n",
      "total sulfur dioxide    6463 non-null float64\n",
      "density                 6463 non-null float64\n",
      "pH                      6463 non-null float64\n",
      "sulphates               6463 non-null float64\n",
      "alcohol                 6463 non-null float64\n",
      "quality                 6463 non-null int64\n",
      "binaryQuality           6463 non-null int64\n",
      "dtypes: float64(11), int64(2), object(1)\n",
      "memory usage: 757.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 데이터와 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train에 적재하기 위한 2차원 배열의 특성 dataset을 만든다.\n",
    "#6463*11(?) 사이즈\n",
    "\n",
    "#실험의 편의성을 위해 data마다 이름을 붙였다.\n",
    "f1=data['fixed acidity']\n",
    "f2=data['volatile acidity']\n",
    "f3=data['citric acid']\n",
    "f4=data['residual sugar']\n",
    "f5=data['chlorides']\n",
    "f6=data['free sulfur dioxide']\n",
    "f7=data['total sulfur dioxide']\n",
    "f8=data['density']\n",
    "f9=data['pH']\n",
    "f10=data['sulphates']\n",
    "f11=data['alcohol']\n",
    "\n",
    "\n",
    "c_data=np.c_[f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train, X_test, y_train, y_test = train_test_split(c_data, data[\\'binaryQuality\\'],random_state=0)\\n\\nprint \"X_train \\xed\\x81\\xac\\xea\\xb8\\xb0: \", X_train.shape #(#(numbe) of data*75%, # of features)\\nprint \"y_train \\xed\\x81\\xac\\xea\\xb8\\xb0: \", y_train.shape #x\\xed\\x8a\\xb8\\xeb\\xa0\\x88\\xec\\x9d\\xb8 \\xeb\\x8d\\xb0\\xec\\x9d\\xb4\\xed\\x84\\xb0\\xec\\x97\\x90 \\xeb\\x8c\\x80\\xed\\x95\\x9c \\xec\\xa0\\x95\\xeb\\x8b\\xb5\\nprint \"X_test \\xed\\x81\\xac\\xea\\xb8\\xb0: \", X_test.shape\\nprint \"y_test \\xed\\x81\\xac\\xea\\xb8\\xb0: \", y_test.shape\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(c_data, data['quality'],random_state=0)\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 삭제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "##우리 데이터는 수치형!\n",
    "fvalue_selector = SelectKBest(f_classif, k=5)\n",
    "##이걸 쓰려니까 f5(염화물)이 constant하다고 나와서 f5제외했음? 될때도있네\n",
    "features_kbest = fvalue_selector.fit_transform(c_data, data['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 11\n",
      "줄어든 특성 개수: 5\n"
     ]
    }
   ],
   "source": [
    "print\"원본 특성 개수:\", c_data.shape[1]\n",
    "print\"줄어든 특성 개수:\", features_kbest.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (4847, 5)\n",
      "y_train 크기:  (4847,)\n",
      "X_test 크기:  (1616, 5)\n",
      "y_test 크기:  (1616,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_kbest, data['quality'],random_state=0)\n",
    "\n",
    "print \"X_train 크기: \", X_train.shape #(#(numbe) of data*75%, # of features)\n",
    "print \"y_train 크기: \", y_train.shape #x트레인 데이터에 대한 정답\n",
    "print \"X_test 크기: \", X_test.shape\n",
    "print \"y_test 크기: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OvA를 사용하여 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=100000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "lin_clf = LinearSVC(max_iter=100000, random_state=42)\n",
    "lin_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 set에 대한 예측을 만들어 정확도를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5141324530637508"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lin_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)\n",
    "##(11개)quality로 했을 때: 0.5188776562822365\n",
    "##(9개)quality로 했을 때: 0.5283680627192078\n",
    "##(7개)quality로 했을 때: 0.5203218485661234\n",
    "##(5개)quality로 했을 때: 0.5141324530637508\n",
    "\n",
    "##(11개)이진분류: 0.7437590262017743\n",
    "##(9개)이진분류: 0.7313802351970291\n",
    "##(7개)이진분류: 0.7317928615638539\n",
    "##(5개)이진분류: 0.7198266969259336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data의 scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = scaler.transform(X_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=100000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(max_iter=100000, random_state=42)\n",
    "lin_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230039199504848"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)\n",
    "##(11개)quality로 했을 때: 0.5289870022694451\n",
    "##(9개)quality로 했을 때: 0.5302248813699195\n",
    "##(7개)quality로 했을 때: 0.5242417990509594\n",
    "##(5개)quality로 했을 때: 0.5230039199504848\n",
    "\n",
    "##(11개)이진분류: 0.7404580152671756\n",
    "##(9개)이진분류: 0.7439653393851867\n",
    "##(7개)이진분류: 0.7435527130183619\n",
    "##(5개)이진분류: 0.7412832680008252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF 커널 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(gamma='auto', decision_function_shape=\"ovr\")\n",
    "svm_clf.fit(X_train_scaled[:4847], y_train[:4847]) ##4847개 data로 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5541572106457603"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)\n",
    "##(11개)quality로 했을 때: 0.6075923251495771\n",
    "##(9개)quality로 했을 때: 0.594800907778007\n",
    "##(7개)quality로 했을 때: 0.5737569630699402\n",
    "##(5개)quality로 했을 때: 0.5541572106457603\n",
    "\n",
    "##(11개)이진분류: 0.796162574788529\n",
    "##(9개)이진분류: 0.7924489374871054\n",
    "##(7개)이진분류: 0.7815143387662472\n",
    "##(5개)이진분류: 0.7542809985558078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증 이용한 랜덤 서치로 hyper parameter 튜닝\n",
    "\n",
    "test 위해 1000개만 해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.9s finished\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f31f8c38fd0>, 'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f31f8c38350>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, cv=3, n_iter=10, verbose=2, n_jobs=-1)\n",
    "rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=7.10578688054794, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.03907162851981535,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_\n",
    "##(11개)quality로 했을 때: 0.523\n",
    "##(9개)quality로 했을 때: 0.521\n",
    "##(7개)quality로 했을 때: 0.516\n",
    "##(5개)quality로 했을 때: 0.518\n",
    "\n",
    "##(11개)이진분류: 0.745\n",
    "##(9개)이진분류: 0.753\n",
    "##(7개)이진분류: 0.749\n",
    "##(5개)이진분류: 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000개만 해서 그런가 낮다.  \n",
    "이제 전체에 대해 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=7.10578688054794, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.03907162851981535,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5438415514751392"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)\n",
    "##(11개)quality로 했을 때: 0.5970703527955437\n",
    "##(9개)quality로 했을 때: 0.5320817000206313\n",
    "##(7개)quality로 했을 때: 0.5479678151433877\n",
    "##(5개)quality로 했을 때: 0.5438415514751392\n",
    "\n",
    "##(11개)이진분류: 0.8116360635444605\n",
    "##(9개)이진분류: 0.7831648442335465\n",
    "##(7개)이진분류: 0.7672787291107902\n",
    "##(5개)이진분류: 0.7478852898700227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5544554455445545"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)\n",
    "##(11개)quality로 했을 때: 0.5792079207920792\n",
    "##(9개)quality로 했을 때: 0.5482673267326733\n",
    "##(7개)quality로 했을 때: 0.557549504950495\n",
    "##(5개)quality로 했을 때: 0.5544554455445545\n",
    "\n",
    "##(11개)이진분류: 0.7803217821782178\n",
    "##(9개)이진분류: 0.7648514851485149\n",
    "##(7개)이진분류: 0.7660891089108911\n",
    "##(5개)이진분류: 0.7561881188118812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형SVM회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=10000,\n",
       "     random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svr = LinearSVR(max_iter=10000, random_state=42)\n",
    "lin_svr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 세트에 대한 데이터 성능\n",
    "\n",
    "MSE란?\n",
    "- 손실함수: 정답에 대한 오류를 숫자로 나타내는 것\n",
    "- 오답에 가까울 수록 큰 값이 나온다.\n",
    "- <span style=\"color:red\">정답에 가까울 수록 작은 값이 나온다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19523842574453554"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = lin_svr.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mse\n",
    "##(11개)quality로 했을 때:0.5565858986694731\n",
    "##(11개)이진분류: 0.19523842574453554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE\n",
    "- 평균 제곱근 오차\n",
    "- 회귀 모델 평가시 사용\n",
    "- 표준편차와 동일, 특정 수치에 대한 예측의 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44185792484070663"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mse)\n",
    "##(11개)quality로 했을 때:0.7460468475032068 -- 타깃이 0~10(3~9)\n",
    "##(11개)이진분류: 0.44185792484070663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 타깃이 0(5이하) 또는 1(6이상)이었기 때문에 저정도의 에러는 우리의 모델을 정확하게 분류할 수 없다고 판단. 거의 찍는 수준??\n",
    "오류가 감소하긴 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유사도 함수를 이용한 SVM 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유사도 함수로 RBF 커널 이용.\n",
    "\n",
    "\n",
    "- 유사도 함수란? : 각 샘플이 특정 랜드마크와 얼마나 닮았는지 측정하는 것\n",
    "    - 비선형 특성을 다루는 기법 중 하나로 유사도 함수로 계산한 특성을 추가한다.\n",
    "\n",
    "\n",
    "- 랜드마크 선택 방법\n",
    "    - 간단한 방법으로 모든 샘플 위치에 랜드마크 설정 ㅡ> __차원이 매우 커진다__\n",
    "    - 차원이 매우 커지기 때문에 변환된 훈련 세트가 선형적으로 구분될 _가능성_ 이 높다.\n",
    "    \n",
    "    \n",
    "- RBF란?\n",
    "    - 방사 기저 함수(라는 이름을 가지고있다)\n",
    "    \n",
    "\n",
    "- 하이퍼파라미터 C와 gamma의 적절한 값을 찾기 위해 교차 검증을 사용한 랜덤 서치를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f31fab0dd10>, 'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f31fab0dc90>},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, cv=3, n_iter=10, verbose=2, random_state=42, n_jobs=-1)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.2058449429580245, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma=0.0870602087830485, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 세트에서 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3691439141701268"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "np.sqrt(mse)\n",
    "##(11개)quality로 했을 때:0.5999828200344473\n",
    "##(11개)이진분류: 0.3691439141701268"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오류가 감소하였으므로 이 모델을 test에 적용해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 세트에서 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40441321433989735"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "np.sqrt(mse)\n",
    "##(11개)quality로 했을 때:0.6670272964753355\n",
    "##(11개)이진분류: 0.40441321433989735"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이정도 오류가 나왔을 때 어떤 수준인지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
